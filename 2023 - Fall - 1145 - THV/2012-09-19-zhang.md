---
date: 2023-09-19
contributor: Zhang
tags: 
  - Autonomous Vehicles
  - Trolley Problem
---
# Administrative
We will always have at least two weeks in between short writing assignments
## Announcements
First short writing assignment due date extended to 10/1/2023 11:59pm
- We have the weekend, but John will not be as responsive on email after 4pm

Office hours today are virtual
## Upcoming Readings and Assignments
For next class
- Asaro: "Autonomous Weapons and the Ethics of Artificial Intelligence"
# News and Events
- Marines lost a F-35 on auto-pilot after a training mishap. They found the wreck in South Carolina.
- Unity is now charging per game install
- John Deere is gatekeeping repairs to their tractors; Apple backed that
# Autonomous Vehicles
How should we program cars to behave in accident scenarios?

Things to consider with autonomous vehicles
- Labor, environment, justice, accident scenarios (vs trolley cases), safety

People who think trolley cases are very helpful vs not = trolley optimists vs trolley pessimists

Two types of trolley optimists: democratic (moral machine) or philosophical

Accident scenario: a situation with an AV where an accident is unavoidable

Difference between AV and human is that humans make immediate, sometimes irrational decisions
## Trolley cases
There are many trolley cases. Here are two examples: 
- Trolley case (switch): train on track to kill five people, a switch to change tracks will kill one person – what should a bystander do?
- Trolley case (bridge): do you push this heavy guy off a bridge to save three pedestrians?

What's your judgment? Is each action permissible, impermissible, or obligatory?

## Trolley problem
- Utilitarian: maximize total happiness
- Don't use a person as a tool

## Trolley optimism
Motivations for trolley optimism: intuitive case vs negligence (Lin)
- Democratic trolley optimists say put it up to a vote
- Philosophical trolley optimists say find the right answer

Argument 1: 
1. Trolley cases are tools for determining what we should do
2. Some accident scenarios are morally like trolley cases
3. If (1) and (2), then we should use trolley cases to directly inform how AVs are programmed to behave in accident scenarios

-- CONCLUSION --

4. So, we should use trolley cases to directly inform how AVs are programmed to behave in accident scenarios

Structure for argument 1:
1. A
2. B
3. If A and B, then C

-- CONCLUSION --

4. C

Argument 2 (Lin):
1. If we the power to program cars to manage accident scenarios in morally better or worse ways, we are obligated to do so
2. We have the power
3. So, we have an obligation to do so
4. Trolley cases are the best tools for determining how we can program them
5. If trolley cases are the best tools for determining how we can program them, then trolley optimism

-- CONCLUSION --

6. Therefore, trolley optimism

Structure for argument 2: 
1. If A, then B
2. A
3. B
4. C
5. If C, then D

-- CONCLUSION --

6. D

Every form of trolley pessimism rejects one of these premises

## Trolley pessimism
Motivations for trolley pessimism: 
- Skepticism about thought experiments (Lin)
- Disanalogy objection (N and S)
- Tech objections (John)

## Moral machine
Moral machine: democratic vote
- Some people just think it’s interesting to see how different cultures value diff things
- Democratic trolley optimists want to use the results to program cars like that

Ethics:
- Descriptive (empirical question about people’s beliefs)
- Prescriptive (what should we do)

Think for yourself: is moral machine a useful tool for answering descriptive ethical questions about accident scenarios? 

Class consensus is NO
- No controls (cannot confirm that answers reflect person’s view)
- Not enough cases (only 13)
- No consistency enforcement
- Not enough variables (race, friends)
- Bias
- Limited sample audience
- No indifference

Imagine that we have a perfect moral machine tool. Is it a good prescriptive tool?

Relativism
- Justifications: argument from mystery, argument from disagreement, argument from tolerance
- Objections: argument from progress, argument from character of disagreement
Legitimacy (reasons we can all accept)
- Argument from legitimacy

Fill in the ? in the following arguments. We will go over them at the beginning of next class.
### Argument from mystery
1. It is mysterious what could make moral claims true or false other than opinion
2. ?

-- CONCLUSION --

3. Therefore, morality is just a matter of opinion/ moral truths are relevant to people’s opinions (relativism is true)

### Argument from disagreement
1. If there is disagreement over ethical issues, then relativism is true
2. ?

-- CONCLUSION --

3. Therefore, relativism is true

### Argument from tolerance
1. If we should be tolerant of the moral views of others, relativism is true
2. ?

-- CONCLUSION --

3. Therefore, relativism is true

## Metaethics
What makes "baby football is wrong" true?
- Note: baby football refers to using a baby as a football

John's shirt is black: this points to an object in the world

Baby football is wrong: this is considered true if someone thinks this is true

This is metaethics
